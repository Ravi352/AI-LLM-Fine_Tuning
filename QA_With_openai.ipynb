{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO4iwGS7YxpaamiMo1soCGC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bmi3j4IcYAxS"},"outputs":[],"source":["import streamlit as st\n","from langchain.document_loaders.csv_loader import CSVLoader\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.prompts import PromptTemplate\n","from langchain.chat_models import ChatOpenAI\n","from langchain.chains import LLMChain\n","from dotenv import load_dotenv\n","\n","load_dotenv()\n","\n","# 1. Vectorise the sales response csv data\n","loader = CSVLoader(file_path=\"QA_data.csv\")\n","documents = loader.load()\n","\n","embeddings = OpenAIEmbeddings()\n","db = FAISS.from_documents(documents, embeddings)\n","\n","# 2. Function for similarity search\n","\n","\n","def retrieve_info(query):\n","    similar_response = db.similarity_search(query, k=3)\n","\n","    page_contents_array = [doc.page_content for doc in similar_response]\n","\n","    # print(page_contents_array)\n","\n","    return page_contents_array\n","\n","\n","# 3. Setup LLMChain & prompts\n","llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-16k-0613\")\n","\n","template = \"\"\"\n","You are a world class business development representative.\n","I will share a prospect's message with you and you will give me the best answer that\n","I should send to this prospect based on past best practies,\n","and you will follow ALL of the rules below:\n","\n","1/ Response should be very similar or even identical to the past best practies,\n","in terms of length, ton of voice, logical arguments and other details\n","\n","2/ If the best practice are irrelevant, then try to mimic the style of the best practice to prospect's message\n","\n","Below is a message I received from the prospect:\n","{message}\n","\n","Here is a list of best practies of how we normally respond to prospect in similar scenarios:\n","{best_practice}\n","\n","Please write the best response that I should send to this prospect:\n","\"\"\"\n","\n","prompt = PromptTemplate(\n","    input_variables=[\"message\", \"best_practice\"],\n","    template=template\n",")\n","\n","chain = LLMChain(llm=llm, prompt=prompt)\n","\n","\n","# 4. Retrieval augmented generation\n","def generate_response(message):\n","    best_practice = retrieve_info(message)\n","    response = chain.run(message=message, best_practice=best_practice)\n","    return response\n","\n","\n","# 5. Build an app with streamlit\n","def main():\n","    st.set_page_config(\n","        page_title=\"Customer response generator\", page_icon=\":bird:\")\n","\n","    st.header(\"Customer response generator :bird:\")\n","    message = st.text_area(\"customer message\")\n","\n","    if message:\n","        st.write(\"Generating best practice message...\")\n","\n","        result = generate_response(message)\n","\n","        st.info(result)\n","\n","\n","if __name__ == '__main__':\n","    main()\n"]}]}